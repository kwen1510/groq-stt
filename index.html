<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Groq Whisper Turbo Transcriber</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body class="bg-gradient-to-br from-gray-50 to-gray-200 min-h-screen flex flex-col items-center justify-center text-gray-800">
  <div class="bg-white shadow-xl rounded-2xl p-6 w-full max-w-md text-center">
    <h1 class="text-2xl font-bold mb-4">üéß Groq Whisper Transcriber</h1>

    <button id="recordBtn"
      class="px-6 py-3 bg-indigo-600 text-white font-semibold rounded-full shadow hover:bg-indigo-700 transition flex items-center justify-center gap-2 mx-auto">
      <i data-lucide="mic"></i><span>Record</span>
    </button>

    <div id="status" class="mt-4 text-gray-500 text-sm"></div>

    <textarea id="transcript"
      placeholder="Transcribed text will appear here..."
      class="hidden w-full mt-4 border border-gray-300 rounded-lg p-3 resize-none h-40 focus:ring-2 focus:ring-indigo-500 outline-none"></textarea>

    <div id="meta" class="hidden mt-3 text-xs text-gray-500 bg-gray-100 rounded-md p-2 text-left"></div>

    <button id="editBtn"
      class="hidden mt-4 px-4 py-2 text-indigo-600 font-semibold hover:underline transition">
      ‚úèÔ∏è Edit Transcript
    </button>

    <button id="deleteKeyBtn"
      class="hidden mt-4 text-red-500 text-sm hover:underline">üóùÔ∏è Delete API Key</button>
  </div>

  <script>
    lucide.createIcons();

    const recordBtn = document.getElementById('recordBtn');
    const statusDiv = document.getElementById('status');
    const transcriptArea = document.getElementById('transcript');
    const metaDiv = document.getElementById('meta');
    const editBtn = document.getElementById('editBtn');
    const deleteKeyBtn = document.getElementById('deleteKeyBtn');

    let mediaRecorder;
    let chunks = [];
    let isRecording = false;
    const WHISPER_MODEL = "whisper-large-v3-turbo";

    // üóùÔ∏è API Key Handling (Session Storage)
    function getAPIKey() {
      let key = sessionStorage.getItem("groq_api_key");
      if (!key) {
        key = prompt("Enter your Groq API Key:");
        if (key && key.trim() !== "") {
          sessionStorage.setItem("groq_api_key", key.trim());
          alert("‚úÖ API Key saved for this session!");
        } else {
          alert("‚ùå No API key provided. Reload to try again.");
        }
      }
      return key;
    }

    function deleteAPIKey() {
      sessionStorage.removeItem("groq_api_key");
      alert("üóùÔ∏è API key deleted from session storage.");
      location.reload();
    }

    // üöÄ Handle /deletekey route
    if (window.location.pathname.endsWith("/deletekey")) {
      deleteAPIKey();
    }

    // üéôÔ∏è Recording Logic
    recordBtn.addEventListener('click', async () => {
      if (!isRecording) startRecording();
      else stopRecording();
    });

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        chunks = [];

        mediaRecorder.ondataavailable = e => chunks.push(e.data);
        mediaRecorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });
          const file = new File([blob], 'recording.webm', { type: 'audio/webm' });
          await transcribeAudio(file);
        };

        mediaRecorder.start();
        isRecording = true;
        recordBtn.querySelector('i').setAttribute('data-lucide', 'square');
        lucide.createIcons();
        recordBtn.querySelector('span').textContent = 'Stop';
        statusDiv.textContent = 'üéôÔ∏è Recording... Speak now.';
      } catch (err) {
        statusDiv.textContent = 'Error accessing microphone.';
        console.error(err);
      }
    }

    function stopRecording() {
      if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        recordBtn.querySelector('i').setAttribute('data-lucide', 'mic');
        lucide.createIcons();
        recordBtn.querySelector('span').textContent = 'Record';
        statusDiv.textContent = 'Processing audio...';
      }
    }

    async function transcribeAudio(file) {
      const apiKey = getAPIKey();
      if (!apiKey) return;

      const formData = new FormData();
      formData.append("file", file);
      formData.append("model", WHISPER_MODEL);
      formData.append("temperature", "0");
      formData.append("response_format", "verbose_json");

      try {
        const res = await fetch("https://api.groq.com/openai/v1/audio/transcriptions", {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`
          },
          body: formData
        });

        const data = await res.json();
        if (!data.text) throw new Error("No text field in response");

        transcriptArea.value = data.text;
        transcriptArea.classList.remove("hidden");
        metaDiv.classList.remove("hidden");
        editBtn.classList.remove("hidden");
        deleteKeyBtn.classList.remove("hidden");

        metaDiv.innerHTML = `
          <p><strong>Language:</strong> ${data.language || "unknown"}</p>
          <p><strong>Duration:</strong> ${data.duration ? data.duration.toFixed(2) + "s" : "N/A"}</p>
        `;

        statusDiv.textContent = "‚úÖ Transcription complete!";
      } catch (error) {
        statusDiv.textContent = "‚ùå Error during transcription.";
        console.error(error);
      }
    }

    editBtn.addEventListener('click', () => {
      transcriptArea.removeAttribute('readonly');
      transcriptArea.focus();
      statusDiv.textContent = "You can now edit your text.";
    });

    deleteKeyBtn.addEventListener('click', deleteAPIKey);
  </script>
</body>
</html>
